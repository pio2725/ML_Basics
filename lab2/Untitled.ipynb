{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "average-destination",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "going-sacramento",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(BaseEstimator,ClassifierMixin):\n",
    "\n",
    "    def __init__(self,lr, momentum, shuffle,hidden_layer_widths, Deterministic, random_weights, binaryClassification):\n",
    "        \"\"\" Initialize class with chosen hyperparameters.\n",
    "\n",
    "        Args:\n",
    "            lr (float): A learning rate / step size.\n",
    "            shuffle(boolean): Whether to shuffle the training data each epoch. DO NOT SHUFFLE for evaluation / debug datasets.\n",
    "            momentum(float): The momentum coefficent \n",
    "        Optional Args (Args we think will make your life easier):\n",
    "            hidden_layer_widths (list(int)): A list of integers which defines the width of each hidden layer if hidden layer is none do twice as many hidden nodes as input nodes.\n",
    "        Example:\n",
    "            mlp = MLPClassifier(lr=.2,momentum=.5,shuffle=False,hidden_layer_widths = [3,3]),  <--- this will create a model with two hidden layers, both 3 nodes wide\n",
    "        \"\"\"\n",
    "        self.hidden_layer_widths = hidden_layer_widths\n",
    "        self.lr = lr\n",
    "        self.momentum = momentum\n",
    "        self.shuffle = shuffle\n",
    "        self.deterministic=Deterministic\n",
    "        self.random_weights=random_weights\n",
    "        self.weights=None\n",
    "        self.delta_weights=None\n",
    "        self.binaryClassification=binaryClassification\n",
    "        self.x_valid=None\n",
    "        self.y_valid=None\n",
    "        self.x_test=None\n",
    "        self.y_test=None\n",
    "\n",
    "\n",
    "    def fit(self, X, y, output_size, initial_weights=None):\n",
    "        \"\"\" Fit the data; run the algorithm and adjust the weights to find a good solution\n",
    "\n",
    "        Args:\n",
    "            X (array-like): A 2D numpy array with the training data, excluding targets\n",
    "            y (array-like): A 2D numpy array with the training targets\n",
    "        Optional Args (Args we think will make your life easier):\n",
    "            initial_weights (array-like): allows the user to provide initial weights\n",
    "        Returns:\n",
    "            self: this allows this to be chained, e.g. model.fit(X,y).predict(X_test)\n",
    "\n",
    "        \"\"\"\n",
    "        #self.initial_weights = self.initialize_weights() if not initial_weights else initial_weights\n",
    "        \n",
    "        self.input_size=X.shape[1]\n",
    "        self.output_size=output_size\n",
    "        if self.weights is None:\n",
    "            self.initialize_weights()\n",
    "            self.delta_weights=self.get_zero_weights()\n",
    "            \n",
    "        if self.deterministic:\n",
    "            self.epochs=10\n",
    "        else:\n",
    "            self.epochs=sys.maxsize\n",
    "            \n",
    "        self.epoch_count=0    \n",
    "        \n",
    "        curr_valid_score = -1\n",
    "        valid_count=0\n",
    "        self.mse_training=[]\n",
    "        self.mse_valid=[]\n",
    "        self.accuracy_train=[]\n",
    "        self.accuracy_valid=[]\n",
    "        #print(\"y is \", y)\n",
    "        #print(\"self.epochs \", self.epochs)\n",
    "        \n",
    "        # Infinite loop when determin is false\n",
    "        for _ in range(self.epochs):\n",
    "\n",
    "            curr_delta_weights=[]\n",
    "            for i in range(y.shape[0]):\n",
    "                #print(\"i = \", i)\n",
    "                input_x = np.insert(X[i], len(X[i]), 1) # Add the bias of 1\n",
    "                # Forwarding\n",
    "                nets = [] \n",
    "                outs = [] \n",
    "                for num_layer in range(len(self.weights)):\n",
    "                    if num_layer == 0:\n",
    "                        net = self.get_nets(input_x, num_layer)\n",
    "                    else:\n",
    "                        net = self.get_nets(out, num_layer)                    \n",
    "                    nets.append(net) \n",
    "                    out = self.activation_sigmoid(net)\n",
    "                    if num_layer != len(self.weights)-1:\n",
    "                        out.append(1) # bias\n",
    "                    outs.append(out)\n",
    "                #print(\"nets \", nets)\n",
    "                # get the output error\n",
    "                output_out = outs[-1] # 1-d array\n",
    "                output_out = np.array(output_out)\n",
    "                #print(\"output_out \", output_out)\n",
    "                '''\n",
    "                temp_errors=[]\n",
    "                expected = [0 for i in range(len(output_out))]\n",
    "                expected[int(y[i][0])]=1\n",
    "                for node_num in range(len(output_out)):\n",
    "                    eee = (expected[node_num] - output_out[node_num]) * output_out[node_num] * (1 - output_out[node_num])\n",
    "                    temp_errors.append(eee)\n",
    "                #output_error = np.array(temp_errors)\n",
    "                #print(\"output error \", output_error)\n",
    "                '''\n",
    "                temp_errors=[]\n",
    "                input_target = y[i] # 1-d array\n",
    "                #print(\"target: \", input_target)\n",
    "                #temp_targets=[0]*self.output_size\n",
    "                #temp_targets[input_target] = 1\n",
    "                #print(\"input_target\", input_target)\n",
    "                #for node_num in range(len(output_out)):\n",
    "                #    eee = (input_target - output_out[node_num])*output_out[node_num]*(1-output_out[node_num])\n",
    "                #    print(\"input target: \", input_target, \"output[num_node] :\", output_out[node_num])\n",
    "                #    temp_errors.append(eee)\n",
    "                \n",
    "                #output_error = np.array(temp_errors)\n",
    "                output_error = (input_target-output_out)*output_out*(1-output_out)\n",
    "                #print(\"1: \", input_target-output_out, \"2: \", output_out*(1-output_out))\n",
    "                #print(\"output error \", output_error)\n",
    "\n",
    "                # Backward\n",
    "                errors = []\n",
    "                self.get_errors(errors, output_error, outs)\n",
    "                self.update_weights(errors, outs, input_x)\n",
    "                #print(\"weights \", self.weights)\n",
    "                \n",
    "                \n",
    "            self.epoch_count += 1 \n",
    "            \n",
    "            # Debug and Eval model do not go through here\n",
    "            # check validation score\n",
    "            if self.x_valid is not None:\n",
    "                valid_score = self.score(self.x_valid, self.y_valid)\n",
    "                \n",
    "                pred_training = self.predict(self.x_test) # prediction using current weight\n",
    "                self.mse_training.append(mean_squared_error(self.y_test, pred_training))\n",
    "                self.mse_valid.append(mean_squared_error(self.y_valid, self.predict(self.x_valid)))\n",
    "                self.accuracy_train.append(self.score(self.x_test, self.y_test))\n",
    "                self.accuracy_valid.append(valid_score)\n",
    "                \n",
    "                if curr_valid_score < valid_score:\n",
    "                    curr_valid_score = valid_score  # 현재까지의 최대 점수를 저장\n",
    "                    valid_count = 0\n",
    "                    self.curr_best_weight = self.weights\n",
    "                #elif abs(curr_valid_score - valid_score) < 0.02:\n",
    "                #    valid_count += 1\n",
    "                if valid_score <= curr_valid_score or abs(curr_valid_score - valid_score) < 0.05:\n",
    "                    valid_count += 1\n",
    "                    \n",
    "                    \n",
    "                # 만약 현재 최고점수에서 다음에 떨어지면 +1\n",
    "                # 현재 최고점수에서 10번동안 아무런 변동이 거의 없다면 끝\n",
    "                \n",
    "\n",
    "                print(\"epochs \", self.epoch_count)\n",
    "                print(\"valid score \", valid_score)\n",
    "                print(\"valid count \", valid_count)\n",
    "                if valid_count == 15:\n",
    "                    print(\"done\")\n",
    "                    break\n",
    "                \n",
    "                \n",
    "            #if self.shuffle:\n",
    "             #   X,y=self._shuffle_data(X,y)\n",
    "                    \n",
    "                    \n",
    "        return self\n",
    "    \n",
    "    def update_weights(self, errors, outs, input_x):\n",
    "        err = errors.copy()\n",
    "        err.reverse()\n",
    "        out = outs.copy()\n",
    "        out.insert(0, input_x)\n",
    "        del out[-1]\n",
    "        \n",
    "        for num_layer in range(len(self.weights)):\n",
    "            w = self.weights[num_layer]\n",
    "            e = err[num_layer]\n",
    "            o = out[num_layer]\n",
    "            \n",
    "            temp_delta=[]\n",
    "            curr_delta = self.delta_weights[num_layer]\n",
    "            #print(\"o \", out[num_layer])\n",
    "            #print(\"e \", err[num_layer])\n",
    "            for i in range(len(o)):\n",
    "                temp=[]\n",
    "                for j in range(len(e)):\n",
    "                    #print(\"e[j]\", e[j], \"o[i] \", o[i])\n",
    "                    v = self.lr*e[j]*o[i] \n",
    "                    #print(\"v: \", v)\n",
    "                    m = self.momentum*curr_delta[i][j]\n",
    "                    #print(\"m : \", m)\n",
    "                    temp.append(v+m)\n",
    "                    #print(\"temp \", temp)\n",
    "                temp_delta.append(temp)\n",
    "            #print(\"num_layer \", num_layer)\n",
    "            self.weights[num_layer] = self.weights[num_layer] + np.array(temp_delta) \n",
    "            self.delta_weights[num_layer] = temp_delta\n",
    "\n",
    "    def get_errors(self, errors, output_error, outs):\n",
    "        errors.append(output_error.tolist())\n",
    "        w = self.weights.copy()\n",
    "        w = w.tolist()\n",
    "        w.reverse()\n",
    "        o_nodes = outs.copy()\n",
    "        o_nodes.reverse()\n",
    "        del o_nodes[0] \n",
    "        num_layers = len(self.weights)\n",
    "        for layer in range(num_layers-1):\n",
    "            error=[]\n",
    "            prev_errors = np.array(errors[-1])\n",
    "            curr_outs = o_nodes[layer]\n",
    "            weight = w[layer]\n",
    "            #print(\"prev_errors \", prev_errors)\n",
    "            for i in range(len(curr_outs)-1):\n",
    "                s = 0\n",
    "                for j in range(len(prev_errors)):\n",
    "                    #print(\"prev[j] \", prev_errors[j], \"weight[i][j]: \", weight[i][j])\n",
    "                    s = s + prev_errors[j]*weight[i][j]\n",
    "                e = s*self.get_der_sig(curr_outs[i])\n",
    "                error.append(e)\n",
    "            errors.append(error)        \n",
    "    \n",
    "    def get_der_sig(self, value):\n",
    "        return value*(1-value)\n",
    "   \n",
    "    def activation_sigmoid(self, net):\n",
    "        outs=[]\n",
    "        for i in range(len(net)):\n",
    "            val = 1.0/(1.0 + np.exp(-net[i]))\n",
    "            outs.append(val)\n",
    "        return outs\n",
    "    \n",
    "    def get_nets(self, x, num_layer):\n",
    "        num_nodes = self.weights[num_layer].shape[1]\n",
    "        nets = []\n",
    "        weight_layer = self.weights[num_layer]\n",
    "        for i in range(num_nodes):\n",
    "            col = weight_layer[:,i]  \n",
    "            dot_product = np.dot(x, col)\n",
    "            nets.append(dot_product)\n",
    "        return nets\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\" Predict all classes for a dataset X\n",
    "        Args:\n",
    "            X (array-like): A 2D numpy array with the training data, excluding targets\n",
    "        Returns:\n",
    "            array, shape (n_samples,)\n",
    "                Predicted target values per element in X.\n",
    "        \"\"\"\n",
    "        preds=[]\n",
    "        for i in range(X.shape[0]):\n",
    "            x = np.insert(X[i], len(X[i]), 1)\n",
    "            nets = [] \n",
    "            outs = []\n",
    "            for num_layer in range(len(self.weights)):\n",
    "                if num_layer == 0:\n",
    "                    net = self.get_nets(x, num_layer)\n",
    "                else:\n",
    "                    net = self.get_nets(out, num_layer)\n",
    "                nets.append(net)  \n",
    "                out = self.activation_sigmoid(net)\n",
    "                \n",
    "                if num_layer != len(self.weights)-1:\n",
    "                    out.append(1) # bias\n",
    "                outs.append(out)\n",
    "                \n",
    "            output_out = outs[-1] # 1-d array\n",
    "            output_out = np.array(output_out)\n",
    "            index = output_out.argmax()\n",
    "            preds.append(index)\n",
    "        return preds\n",
    "            \n",
    "              \n",
    "    \n",
    "    def get_zero_weights(self):\n",
    "        self.layer_size = 2 + len(self.hidden_layer_widths)\n",
    "        self.node_size_list = [self.input_size + 1] # input nodes + bias\n",
    "        for i in range(len(self.hidden_layer_widths)):\n",
    "            self.node_size_list.append(self.hidden_layer_widths[i] + 1)\n",
    "        if self.binaryClassification:\n",
    "            self.node_size_list.append(self.output_size+1)\n",
    "        else:\n",
    "            self.node_size_list.append(self.output_size)\n",
    "        weights = np.empty(self.layer_size-1, dtype=np.ndarray)\n",
    "                \n",
    "        for i in range(len(self.node_size_list) - 1):\n",
    "            \n",
    "            if i == len(self.node_size_list)-2:\n",
    "                x=self.node_size_list[i]\n",
    "                y=self.node_size_list[i+1]\n",
    "            else:\n",
    "                x=self.node_size_list[i]\n",
    "                y=self.node_size_list[i+1]-1\n",
    "            \n",
    "            weights[i]=np.zeros((x,y))\n",
    "            \n",
    "        return weights\n",
    "    \n",
    "        \n",
    "\n",
    "    def initialize_weights(self):\n",
    "        \"\"\" Initialize weights for perceptron. Don't forget the bias!\n",
    "\n",
    "        Returns:\n",
    "\n",
    "        \"\"\"\n",
    "        if self.random_weights:\n",
    "            self.layer_size = 2 + len(self.hidden_layer_widths)\n",
    "            self.node_size_list = [self.input_size + 1] # input nodes + bias\n",
    "            for i in range(len(self.hidden_layer_widths)):\n",
    "                self.node_size_list.append(self.hidden_layer_widths[i] + 1)\n",
    "            if self.binaryClassification:\n",
    "                self.node_size_list.append(self.output_size+1)\n",
    "            else:\n",
    "                self.node_size_list.append(self.output_size)\n",
    "            weights = np.empty(self.layer_size-1, dtype=np.ndarray)\n",
    "                \n",
    "            for i in range(len(self.node_size_list) - 1):\n",
    "            \n",
    "                if i == len(self.node_size_list)-2:\n",
    "                    x=self.node_size_list[i]\n",
    "                    y=self.node_size_list[i+1]\n",
    "                else:\n",
    "                    x=self.node_size_list[i]\n",
    "                    y=self.node_size_list[i+1]-1\n",
    "            \n",
    "                weights[i]=np.random.uniform(-1,1,(x,y))\n",
    "            self.weights = weights\n",
    "        else:\n",
    "            # random zeros\n",
    "            self.weights = self.get_zero_weights()\n",
    "            \n",
    "        return [0]\n",
    "\n",
    "    def score(self, X, y):\n",
    "        \"\"\" Return accuracy of model on a given dataset. Must implement own score function.\n",
    "\n",
    "        Args:\n",
    "            X (array-like): A 2D numpy array with data, excluding targets\n",
    "            y (array-like): A 2D numpy array with targets\n",
    "\n",
    "        Returns:\n",
    "            score : float\n",
    "                Mean accuracy of self.predict(X) wrt. y.\n",
    "        \"\"\"\n",
    "        preds = self.predict(X)\n",
    "        temp_y = np.reshape(y, (y.shape[1], y.shape[0]))\n",
    "        #print(\"preds \", preds)\n",
    "        #print(\"y test \", temp_y)\n",
    "        return np.count_nonzero(preds == temp_y[0,:]) / len(preds)\n",
    "    \n",
    "    def set_valid_sets(self, x, y):\n",
    "        self.x_valid=x\n",
    "        self.y_valid=y\n",
    "        \n",
    "    def set_test_sets(self, x, y):\n",
    "        self.x_test=x\n",
    "        self.y_test=y\n",
    "        \n",
    "    def _shuffle_data(self, X, y):\n",
    "        \"\"\" Shuffle the data! This _ prefix suggests that this method should only be called internally.\n",
    "            It might be easier to concatenate X & y and shuffle a single 2D array, rather than\n",
    "             shuffling X and y exactly the same way, independently.\n",
    "        \"\"\"\n",
    "        # X is 2d array\n",
    "        # y is \n",
    "        X_temp = X\n",
    "        y_temp = y.flatten()\n",
    "        temp = np.column_stack((X_temp, y_temp))\n",
    "        np.random.shuffle(temp)\n",
    "        X_result = temp[:,:-1]\n",
    "        y_result = temp[:,-1]\n",
    "        y_result = np.reshape(y_result, (y_result.shape[0],1))\n",
    "        return X_result, y_result\n",
    "\n",
    "    ### Not required by sk-learn but required by us for grading. Returns the weights.\n",
    "    def get_weights(self):\n",
    "        return self.weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "moved-malta",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array([[-0.00018149, -0.00018149, -0.00018149, -0.00018149],\n",
       "       [ 0.00157468,  0.00157468,  0.00157468,  0.00157468],\n",
       "       [-0.00788218, -0.00788218, -0.00788218, -0.00788218]]),\n",
       "       array([[ 0.01050642, -0.01050642],\n",
       "       [ 0.01050642, -0.01050642],\n",
       "       [ 0.01050642, -0.01050642],\n",
       "       [ 0.01050642, -0.01050642],\n",
       "       [ 0.02148778, -0.02148778]])], dtype=object)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load debug data\n",
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "\n",
    "# Load debug data\n",
    "debug_data = arff.loadarff(\"debug_dataset.arff\")\n",
    "debug_df = pd.DataFrame(debug_data[0])\n",
    "debug_df['class'] = debug_df['class'].str.decode('utf-8')\n",
    "debug_df['class'] = debug_df['class'].apply(pd.to_numeric)\n",
    "np_debug = np.array(debug_df)\n",
    "\n",
    "X_debug = np_debug[:,:-1]\n",
    "y_debug = np_debug[:,-1]\n",
    "y_debug = np.reshape(y_debug, (y_debug.shape[0],1)) # (8,1)\n",
    "encoded_y = onehot_encoder.fit_transform(y_debug)\n",
    "\n",
    "\n",
    "\n",
    "#(self,lr=.1, momentum=0, shuffle=True,hidden_layer_widths=None, Deterministic=True, random_weights=True, binaryClassification=False):\n",
    "# Train on debug data\n",
    "mlp_debug = MLPClassifier(0.1, 0.5, False, [4], True, False, False)\n",
    "mlp_debug = mlp_debug.fit(X_debug, encoded_y,2)\n",
    "\n",
    "# Check weights\n",
    "mlp_debug.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "social-density",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "encoded = onehot_encoder.fit_transform(y_debug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "alleged-chick",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.5,  0.5],\n",
       "       [-0.5,  0.5],\n",
       "       [-0.5,  0.5],\n",
       "       [-0.5,  0.5],\n",
       "       [ 0.5, -0.5],\n",
       "       [ 0.5, -0.5],\n",
       "       [ 0.5, -0.5],\n",
       "       [ 0.5, -0.5]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded-0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfactory-emerald",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
